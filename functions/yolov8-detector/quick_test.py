"""
Quick Test Script

Testa rapidamente o sistema YOLOv8 sem treinamento completo
√ötil para verificar se tudo est√° funcionando

@author Torq AI Team
@version 1.0.0
"""

import os
import sys
from pathlib import Path
import numpy as np
from PIL import Image


def print_header(text):
    """Print formatted header"""
    print("\n" + "=" * 80)
    print(f"  {text}")
    print("=" * 80 + "\n")


def test_imports():
    """Test if all required packages are installed"""
    print("üì¶ Testando imports...")
    
    packages = {
        'ultralytics': 'YOLOv8',
        'fastapi': 'FastAPI',
        'uvicorn': 'Uvicorn',
        'PIL': 'Pillow',
        'numpy': 'NumPy',
        'cv2': 'OpenCV',
        'torch': 'PyTorch',
        'pandas': 'Pandas',
        'matplotlib': 'Matplotlib',
        'seaborn': 'Seaborn',
        'psutil': 'psutil',
        'requests': 'Requests',
        'yaml': 'PyYAML'
    }
    
    failed = []
    
    for package, name in packages.items():
        try:
            __import__(package)
            print(f"  ‚úÖ {name}")
        except ImportError:
            print(f"  ‚ùå {name} (faltando)")
            failed.append(name)
    
    if failed:
        print(f"\n‚ùå Pacotes faltando: {', '.join(failed)}")
        print("Execute: pip install -r requirements.txt")
        return False
    
    print("\n‚úÖ Todos os imports OK!")
    return True


def test_yolov8():
    """Test YOLOv8 basic functionality"""
    print("\nü§ñ Testando YOLOv8...")
    
    try:
        from ultralytics import YOLO
        
        # Load model
        print("  Carregando modelo YOLOv8n...")
        model = YOLO('yolov8n.pt')
        print("  ‚úÖ Modelo carregado")
        
        # Create dummy image
        print("  Criando imagem de teste...")
        dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # Run inference
        print("  Executando infer√™ncia...")
        results = model(dummy_img, verbose=False)
        print("  ‚úÖ Infer√™ncia OK")
        
        # Check results
        detections = len(results[0].boxes) if results[0].boxes is not None else 0
        print(f"  ‚ÑπÔ∏è  Detec√ß√µes: {detections}")
        
        print("\n‚úÖ YOLOv8 funcionando!")
        return True
    
    except Exception as e:
        print(f"\n‚ùå Erro no YOLOv8: {e}")
        return False


def test_gpu():
    """Test GPU availability"""
    print("\nüñ•Ô∏è  Testando GPU...")
    
    try:
        import torch
        
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_count = torch.cuda.device_count()
            print(f"  ‚úÖ GPU dispon√≠vel: {gpu_name}")
            print(f"  ‚ÑπÔ∏è  {gpu_count} GPU(s) detectada(s)")
            
            # Test CUDA
            print("  Testando CUDA...")
            x = torch.rand(5, 3).cuda()
            print("  ‚úÖ CUDA funcionando")
            
            return True
        else:
            print("  ‚ÑπÔ∏è  GPU n√£o dispon√≠vel (usando CPU)")
            return False
    
    except Exception as e:
        print(f"  ‚ö†Ô∏è  Erro ao testar GPU: {e}")
        return False


def test_directories():
    """Test if required directories exist"""
    print("\nüìÅ Testando diret√≥rios...")
    
    required_dirs = [
        'datasets',
        'runs',
        'exports',
        'benchmark_results',
        'model'
    ]
    
    missing = []
    
    for directory in required_dirs:
        path = Path(directory)
        if path.exists():
            print(f"  ‚úÖ {directory}")
        else:
            print(f"  ‚ùå {directory} (faltando)")
            missing.append(directory)
    
    if missing:
        print(f"\n‚ö†Ô∏è  Diret√≥rios faltando: {', '.join(missing)}")
        print("Execute: python setup.py")
        return False
    
    print("\n‚úÖ Todos os diret√≥rios OK!")
    return True


def test_scripts():
    """Test if all scripts exist"""
    print("\nüìÑ Testando scripts...")
    
    required_scripts = [
        'detector.py',
        'train.py',
        'validate_dataset.py',
        'analyze_results.py',
        'export_model.py',
        'benchmark.py',
        'test_detector.py'
    ]
    
    missing = []
    
    for script in required_scripts:
        path = Path(script)
        if path.exists():
            print(f"  ‚úÖ {script}")
        else:
            print(f"  ‚ùå {script} (faltando)")
            missing.append(script)
    
    if missing:
        print(f"\n‚ùå Scripts faltando: {', '.join(missing)}")
        return False
    
    print("\n‚úÖ Todos os scripts OK!")
    return True


def test_inference_speed():
    """Test inference speed"""
    print("\n‚ö° Testando velocidade de infer√™ncia...")
    
    try:
        from ultralytics import YOLO
        import time
        
        model = YOLO('yolov8n.pt')
        dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # Warm up
        print("  Aquecendo...")
        for _ in range(5):
            model(dummy_img, verbose=False)
        
        # Benchmark
        print("  Medindo velocidade...")
        times = []
        for _ in range(20):
            start = time.time()
            model(dummy_img, verbose=False)
            end = time.time()
            times.append((end - start) * 1000)
        
        mean_time = np.mean(times)
        fps = 1000 / mean_time
        
        print(f"\n  Tempo m√©dio: {mean_time:.2f}ms")
        print(f"  FPS estimado: {fps:.1f}")
        
        if mean_time < 50:
            print("  üöÄ Excelente! (Real-time capable)")
        elif mean_time < 100:
            print("  ‚úÖ Bom! (Near real-time)")
        elif mean_time < 250:
            print("  üü° Aceit√°vel (Batch processing)")
        else:
            print("  üî¥ Lento (Considere usar GPU)")
        
        return True
    
    except Exception as e:
        print(f"\n‚ùå Erro no teste de velocidade: {e}")
        return False


def test_api_imports():
    """Test API-related imports"""
    print("\nüåê Testando imports da API...")
    
    try:
        from fastapi import FastAPI
        from uvicorn import run
        print("  ‚úÖ FastAPI")
        print("  ‚úÖ Uvicorn")
        
        print("\n‚úÖ API imports OK!")
        return True
    
    except Exception as e:
        print(f"\n‚ùå Erro nos imports da API: {e}")
        return False


def print_summary(results):
    """Print test summary"""
    print("\n" + "=" * 80)
    print("  üìä Resumo dos Testes")
    print("=" * 80 + "\n")
    
    total = len(results)
    passed = sum(results.values())
    failed = total - passed
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
    
    print(f"\n  Total: {passed}/{total} testes passaram")
    
    if failed == 0:
        print("\n  üéâ Todos os testes passaram!")
        print("  ‚úÖ Sistema pronto para uso!")
    else:
        print(f"\n  ‚ö†Ô∏è  {failed} teste(s) falharam")
        print("  Execute: python setup.py")
    
    print("\n" + "=" * 80)


def main():
    """Main test function"""
    print_header("üß™ YOLOv8 Quick Test")
    
    results = {}
    
    # Run tests
    results['Imports'] = test_imports()
    results['Diret√≥rios'] = test_directories()
    results['Scripts'] = test_scripts()
    results['YOLOv8'] = test_yolov8()
    results['GPU'] = test_gpu()
    results['Velocidade'] = test_inference_speed()
    results['API'] = test_api_imports()
    
    # Print summary
    print_summary(results)
    
    # Exit code
    if all(results.values()):
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == '__main__':
    main()
